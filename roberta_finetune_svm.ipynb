{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 582.993223,
      "end_time": "2021-06-23T06:33:51.008306",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2021-06-23T06:24:08.015083",
      "version": "2.3.3"
    },
    "colab": {
      "name": "roberta-finetune-svm.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/huhji/NLP-Basic/blob/main/roberta_finetune_svm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "execution": {
          "iopub.execute_input": "2021-06-23T06:24:16.217420Z",
          "iopub.status.busy": "2021-06-23T06:24:16.216732Z",
          "iopub.status.idle": "2021-06-23T06:24:16.317742Z",
          "shell.execute_reply": "2021-06-23T06:24:16.316699Z",
          "shell.execute_reply.started": "2021-06-23T06:13:47.953963Z"
        },
        "papermill": {
          "duration": 0.139172,
          "end_time": "2021-06-23T06:24:16.317983",
          "exception": false,
          "start_time": "2021-06-23T06:24:16.178811",
          "status": "completed"
        },
        "tags": [],
        "id": "drawn-stick",
        "outputId": "abd08a81-9278-4171-9c0a-27703a7ce32f"
      },
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ],
      "id": "drawn-stick",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/kaggle/input/commonlit-roberta-base-i/model3.bin\n",
            "/kaggle/input/commonlit-roberta-base-i/model2.bin\n",
            "/kaggle/input/commonlit-roberta-base-i/model1.bin\n",
            "/kaggle/input/commonlit-roberta-base-i/model0.bin\n",
            "/kaggle/input/commonlit-roberta-base-i/model4.bin\n",
            "/kaggle/input/roberta-base/config.json\n",
            "/kaggle/input/roberta-base/merges.txt\n",
            "/kaggle/input/roberta-base/vocab.json\n",
            "/kaggle/input/roberta-base/pytorch_model.bin\n",
            "/kaggle/input/clr-roberta/model0/merges.txt\n",
            "/kaggle/input/clr-roberta/model0/vocab.json\n",
            "/kaggle/input/clr-roberta/model0/tokenizer_config.json\n",
            "/kaggle/input/clr-roberta/model0/model0.bin\n",
            "/kaggle/input/clr-roberta/model0/special_tokens_map.json\n",
            "/kaggle/input/clr-roberta/model2/merges.txt\n",
            "/kaggle/input/clr-roberta/model2/vocab.json\n",
            "/kaggle/input/clr-roberta/model2/tokenizer_config.json\n",
            "/kaggle/input/clr-roberta/model2/model2.bin\n",
            "/kaggle/input/clr-roberta/model2/special_tokens_map.json\n",
            "/kaggle/input/clr-roberta/model3/model3.bin\n",
            "/kaggle/input/clr-roberta/model3/merges.txt\n",
            "/kaggle/input/clr-roberta/model3/vocab.json\n",
            "/kaggle/input/clr-roberta/model3/tokenizer_config.json\n",
            "/kaggle/input/clr-roberta/model3/special_tokens_map.json\n",
            "/kaggle/input/clr-roberta/model1/merges.txt\n",
            "/kaggle/input/clr-roberta/model1/vocab.json\n",
            "/kaggle/input/clr-roberta/model1/tokenizer_config.json\n",
            "/kaggle/input/clr-roberta/model1/model1.bin\n",
            "/kaggle/input/clr-roberta/model1/special_tokens_map.json\n",
            "/kaggle/input/clr-roberta/model4/merges.txt\n",
            "/kaggle/input/clr-roberta/model4/vocab.json\n",
            "/kaggle/input/clr-roberta/model4/tokenizer_config.json\n",
            "/kaggle/input/clr-roberta/model4/model4.bin\n",
            "/kaggle/input/clr-roberta/model4/special_tokens_map.json\n",
            "/kaggle/input/roberta-large-itptfit/model3.bin\n",
            "/kaggle/input/roberta-large-itptfit/model2.bin\n",
            "/kaggle/input/roberta-large-itptfit/model1.bin\n",
            "/kaggle/input/roberta-large-itptfit/model0.bin\n",
            "/kaggle/input/roberta-large-itptfit/model4.bin\n",
            "/kaggle/input/commonlit-roberta-large-ii/model3.bin\n",
            "/kaggle/input/commonlit-roberta-large-ii/model2.bin\n",
            "/kaggle/input/commonlit-roberta-large-ii/model1.bin\n",
            "/kaggle/input/commonlit-roberta-large-ii/model0.bin\n",
            "/kaggle/input/commonlit-roberta-large-ii/model4.bin\n",
            "/kaggle/input/commonlitreadabilityprize/sample_submission.csv\n",
            "/kaggle/input/commonlitreadabilityprize/train.csv\n",
            "/kaggle/input/commonlitreadabilityprize/test.csv\n",
            "/kaggle/input/robertalarge/config.json\n",
            "/kaggle/input/robertalarge/merges.txt\n",
            "/kaggle/input/robertalarge/vocab.json\n",
            "/kaggle/input/robertalarge/pytorch_model.bin\n",
            "/kaggle/input/robertalarge/modelcard.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-23T06:24:16.374016Z",
          "iopub.status.busy": "2021-06-23T06:24:16.372611Z",
          "iopub.status.idle": "2021-06-23T06:24:26.046524Z",
          "shell.execute_reply": "2021-06-23T06:24:26.045379Z",
          "shell.execute_reply.started": "2021-06-23T06:08:02.898099Z"
        },
        "papermill": {
          "duration": 9.703934,
          "end_time": "2021-06-23T06:24:26.046780",
          "exception": false,
          "start_time": "2021-06-23T06:24:16.342846",
          "status": "completed"
        },
        "tags": [],
        "id": "premium-commons"
      },
      "source": [
        "import os\n",
        "import random\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from sklearn.svm import SVR\n",
        "\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import KFold,StratifiedKFold\n",
        "\n",
        "\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import get_cosine_schedule_with_warmup\n",
        "from transformers import (AutoModel,AutoModelForMaskedLM, AutoTokenizer, LineByLineTextDataset,\n",
        "                         DataCollatorForLanguageModeling,Trainer, TrainingArguments,)"
      ],
      "id": "premium-commons",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-23T06:24:26.101942Z",
          "iopub.status.busy": "2021-06-23T06:24:26.101260Z",
          "iopub.status.idle": "2021-06-23T06:24:26.202102Z",
          "shell.execute_reply": "2021-06-23T06:24:26.201081Z",
          "shell.execute_reply.started": "2021-06-23T06:08:08.828028Z"
        },
        "papermill": {
          "duration": 0.131646,
          "end_time": "2021-06-23T06:24:26.202280",
          "exception": false,
          "start_time": "2021-06-23T06:24:26.070634",
          "status": "completed"
        },
        "tags": [],
        "id": "delayed-interpretation"
      },
      "source": [
        "train_data = pd.read_csv('../input/commonlitreadabilityprize/train.csv')\n",
        "test_data = pd.read_csv('../input/commonlitreadabilityprize/test.csv')\n",
        "sample = pd.read_csv('../input/commonlitreadabilityprize/sample_submission.csv')\n",
        "\n",
        "num_bins = int(np.floor(1 + np.log2(len(train_data))))\n",
        "train_data.loc[:,'bins'] = pd.cut(train_data['target'],bins=num_bins,labels=False)\n",
        "\n",
        "target = train_data['target'].to_numpy()\n",
        "bins = train_data.bins.to_numpy()\n",
        "\n",
        "def rmse_score(y_true,y_pred):\n",
        "    return np.sqrt(mean_squared_error(y_true,y_pred))"
      ],
      "id": "delayed-interpretation",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-23T06:24:26.256857Z",
          "iopub.status.busy": "2021-06-23T06:24:26.256004Z",
          "iopub.status.idle": "2021-06-23T06:24:26.264008Z",
          "shell.execute_reply": "2021-06-23T06:24:26.263364Z",
          "shell.execute_reply.started": "2021-06-23T05:49:41.249756Z"
        },
        "papermill": {
          "duration": 0.038323,
          "end_time": "2021-06-23T06:24:26.264141",
          "exception": false,
          "start_time": "2021-06-23T06:24:26.225818",
          "status": "completed"
        },
        "tags": [],
        "id": "alive-midnight"
      },
      "source": [
        "config = {\n",
        "    'batch_size':128,\n",
        "    'max_len':256,\n",
        "    'nfolds':5,\n",
        "    'seed':42,\n",
        "}\n",
        "\n",
        "def seed_everything(seed=42):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONASSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "\n",
        "seed_everything(seed=config['seed'])"
      ],
      "id": "alive-midnight",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-23T06:24:26.318942Z",
          "iopub.status.busy": "2021-06-23T06:24:26.316881Z",
          "iopub.status.idle": "2021-06-23T06:24:26.320068Z",
          "shell.execute_reply": "2021-06-23T06:24:26.320633Z",
          "shell.execute_reply.started": "2021-06-23T05:49:44.473613Z"
        },
        "papermill": {
          "duration": 0.033478,
          "end_time": "2021-06-23T06:24:26.320821",
          "exception": false,
          "start_time": "2021-06-23T06:24:26.287343",
          "status": "completed"
        },
        "tags": [],
        "id": "terminal-peninsula"
      },
      "source": [
        "class CLRPDataset(Dataset):\n",
        "    def __init__(self,df,tokenizer):\n",
        "        self.excerpt = df['excerpt'].to_numpy()\n",
        "        self.tokenizer = tokenizer\n",
        "    \n",
        "    def __getitem__(self,idx):\n",
        "        encode = self.tokenizer(self.excerpt[idx],return_tensors='pt',\n",
        "                                max_length=config['max_len'],\n",
        "                                padding='max_length',truncation=True)\n",
        "        return encode\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.excerpt)"
      ],
      "id": "terminal-peninsula",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-23T06:24:26.377311Z",
          "iopub.status.busy": "2021-06-23T06:24:26.375248Z",
          "iopub.status.idle": "2021-06-23T06:24:26.378479Z",
          "shell.execute_reply": "2021-06-23T06:24:26.379023Z",
          "shell.execute_reply.started": "2021-06-23T05:49:45.412155Z"
        },
        "papermill": {
          "duration": 0.0353,
          "end_time": "2021-06-23T06:24:26.379171",
          "exception": false,
          "start_time": "2021-06-23T06:24:26.343871",
          "status": "completed"
        },
        "tags": [],
        "id": "composite-indicator"
      },
      "source": [
        "class AttentionHead(nn.Module):\n",
        "    def __init__(self, in_features, hidden_dim, num_targets):\n",
        "        super().__init__()\n",
        "        self.in_features = in_features\n",
        "        self.middle_features = hidden_dim\n",
        "\n",
        "        self.W = nn.Linear(in_features, hidden_dim)\n",
        "        self.V = nn.Linear(hidden_dim, 1)\n",
        "        self.out_features = hidden_dim\n",
        "\n",
        "    def forward(self, features):\n",
        "        att = torch.tanh(self.W(features))\n",
        "\n",
        "        score = self.V(att)\n",
        "\n",
        "        attention_weights = torch.softmax(score, dim=1)\n",
        "\n",
        "        context_vector = attention_weights * features\n",
        "        context_vector = torch.sum(context_vector, dim=1)\n",
        "\n",
        "        return context_vector"
      ],
      "id": "composite-indicator",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-23T06:24:26.432999Z",
          "iopub.status.busy": "2021-06-23T06:24:26.431922Z",
          "iopub.status.idle": "2021-06-23T06:24:26.434739Z",
          "shell.execute_reply": "2021-06-23T06:24:26.435302Z",
          "shell.execute_reply.started": "2021-06-23T05:49:46.312760Z"
        },
        "papermill": {
          "duration": 0.033111,
          "end_time": "2021-06-23T06:24:26.435469",
          "exception": false,
          "start_time": "2021-06-23T06:24:26.402358",
          "status": "completed"
        },
        "tags": [],
        "id": "inappropriate-rendering"
      },
      "source": [
        "class Model(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Model,self).__init__()\n",
        "        self.roberta = AutoModel.from_pretrained('../input/roberta-base')    \n",
        "        self.head = AttentionHead(768,768,1)\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self.linear = nn.Linear(self.head.out_features,1)\n",
        "\n",
        "    def forward(self,**xb):\n",
        "        x = self.roberta(**xb)[0]\n",
        "        x = self.head(x)\n",
        "        return x"
      ],
      "id": "inappropriate-rendering",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-23T06:24:26.491613Z",
          "iopub.status.busy": "2021-06-23T06:24:26.490505Z",
          "iopub.status.idle": "2021-06-23T06:24:26.493789Z",
          "shell.execute_reply": "2021-06-23T06:24:26.493210Z",
          "shell.execute_reply.started": "2021-06-23T05:49:47.317259Z"
        },
        "papermill": {
          "duration": 0.035519,
          "end_time": "2021-06-23T06:24:26.493913",
          "exception": false,
          "start_time": "2021-06-23T06:24:26.458394",
          "status": "completed"
        },
        "tags": [],
        "id": "social-builder"
      },
      "source": [
        "def get_embeddings(df,path,plot_losses=True, verbose=True):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(f\"{device} is used\")\n",
        "            \n",
        "    model = Model()\n",
        "    model.load_state_dict(torch.load(path))\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    \n",
        "    tokenizer = AutoTokenizer.from_pretrained('../input/roberta-base')\n",
        "    \n",
        "    ds = CLRPDataset(df,tokenizer)\n",
        "    dl = DataLoader(ds,\n",
        "                  batch_size = config[\"batch_size\"],\n",
        "                  shuffle=False,\n",
        "                  num_workers = 4,\n",
        "                  pin_memory=True,\n",
        "                  drop_last=False\n",
        "                 )\n",
        "        \n",
        "    embeddings = list()\n",
        "    with torch.no_grad():\n",
        "        for i, inputs in tqdm(enumerate(dl)):\n",
        "            inputs = {key:val.reshape(val.shape[0],-1).to(device) for key,val in inputs.items()}\n",
        "            outputs = model(**inputs)\n",
        "            outputs = outputs.detach().cpu().numpy()\n",
        "            embeddings.extend(outputs)\n",
        "    return np.array(embeddings)"
      ],
      "id": "social-builder",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-23T06:24:26.598508Z",
          "iopub.status.busy": "2021-06-23T06:24:26.597634Z",
          "iopub.status.idle": "2021-06-23T06:27:47.244115Z",
          "shell.execute_reply": "2021-06-23T06:27:47.243566Z",
          "shell.execute_reply.started": "2021-06-23T05:50:36.943450Z"
        },
        "papermill": {
          "duration": 200.7272,
          "end_time": "2021-06-23T06:27:47.244289",
          "exception": false,
          "start_time": "2021-06-23T06:24:26.517089",
          "status": "completed"
        },
        "tags": [],
        "id": "broke-tuition",
        "outputId": "7941e65a-b5f3-4a1f-f199-c08fa155a2bb"
      },
      "source": [
        "train_embeddings1 =  get_embeddings(train_data,'../input/clr-roberta/model0/model0.bin')\n",
        "test_embeddings1 = get_embeddings(test_data,'../input/clr-roberta/model0/model0.bin')\n",
        "\n",
        "train_embeddings2 =  get_embeddings(train_data,'../input/clr-roberta/model1/model1.bin')\n",
        "test_embeddings2 = get_embeddings(test_data,'../input/clr-roberta/model1/model1.bin')\n",
        "\n",
        "train_embeddings3 =  get_embeddings(train_data,'../input/clr-roberta/model2/model2.bin')\n",
        "test_embeddings3 = get_embeddings(test_data,'../input/clr-roberta/model2/model2.bin')\n",
        "\n",
        "train_embeddings4 =  get_embeddings(train_data,'../input/clr-roberta/model3/model3.bin')\n",
        "test_embeddings4 = get_embeddings(test_data,'../input/clr-roberta/model3/model3.bin')\n",
        "\n",
        "train_embeddings5 =  get_embeddings(train_data,'../input/clr-roberta/model4/model4.bin')\n",
        "test_embeddings5 = get_embeddings(test_data,'../input/clr-roberta/model4/model4.bin')"
      ],
      "id": "broke-tuition",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda is used\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "23it [00:23,  1.02s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "cuda is used\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1it [00:00,  5.01it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "cuda is used\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "23it [00:22,  1.04it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "cuda is used\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1it [00:00,  5.05it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "cuda is used\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "23it [00:22,  1.04it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "cuda is used\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1it [00:00,  4.86it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "cuda is used\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "23it [00:22,  1.03it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "cuda is used\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1it [00:00,  4.60it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "cuda is used\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "23it [00:22,  1.04it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "cuda is used\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1it [00:00,  3.96it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-23T06:27:47.409063Z",
          "iopub.status.busy": "2021-06-23T06:27:47.408191Z",
          "iopub.status.idle": "2021-06-23T06:27:47.412807Z",
          "shell.execute_reply": "2021-06-23T06:27:47.412220Z",
          "shell.execute_reply.started": "2021-06-23T06:08:21.690116Z"
        },
        "papermill": {
          "duration": 0.091011,
          "end_time": "2021-06-23T06:27:47.412950",
          "exception": false,
          "start_time": "2021-06-23T06:27:47.321939",
          "status": "completed"
        },
        "tags": [],
        "id": "confident-polyester"
      },
      "source": [
        "def get_preds_svm(X,y,X_test,bins=bins,nfolds=5,C=10,kernel='rbf'):\n",
        "    scores = list()\n",
        "    preds = np.zeros((X_test.shape[0]))\n",
        "    \n",
        "    kfold = StratifiedKFold(n_splits=config['nfolds'],shuffle=True,random_state=config['seed'])\n",
        "    for k, (train_idx,valid_idx) in enumerate(kfold.split(X,bins)):\n",
        "        model = SVR(C=C,kernel=kernel,gamma='auto')\n",
        "        X_train,y_train = X[train_idx], y[train_idx]\n",
        "        X_valid,y_valid = X[valid_idx], y[valid_idx]\n",
        "        \n",
        "        model.fit(X_train,y_train)\n",
        "        prediction = model.predict(X_valid)\n",
        "        score = rmse_score(prediction,y_valid)\n",
        "        print(f'Fold {k} , rmse score: {score}')\n",
        "        scores.append(score)\n",
        "        preds += model.predict(X_test)\n",
        "        \n",
        "    print(\"mean rmse\",np.mean(scores))\n",
        "    return np.array(preds)/nfolds"
      ],
      "id": "confident-polyester",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-23T06:27:47.572652Z",
          "iopub.status.busy": "2021-06-23T06:27:47.571904Z",
          "iopub.status.idle": "2021-06-23T06:28:35.637201Z",
          "shell.execute_reply": "2021-06-23T06:28:35.638001Z",
          "shell.execute_reply.started": "2021-06-23T06:08:23.980379Z"
        },
        "papermill": {
          "duration": 48.149251,
          "end_time": "2021-06-23T06:28:35.638266",
          "exception": false,
          "start_time": "2021-06-23T06:27:47.489015",
          "status": "completed"
        },
        "tags": [],
        "id": "modified-gilbert",
        "outputId": "d6b418b9-97c7-43fd-df84-f2f438f7afdc"
      },
      "source": [
        "svm_preds1 = get_preds_svm(train_embeddings1,target,test_embeddings1)\n",
        "svm_preds2 = get_preds_svm(train_embeddings2,target,test_embeddings2)\n",
        "svm_preds3 = get_preds_svm(train_embeddings3,target,test_embeddings3)\n",
        "svm_preds4 = get_preds_svm(train_embeddings4,target,test_embeddings4)\n",
        "svm_preds5 = get_preds_svm(train_embeddings5,target,test_embeddings5)"
      ],
      "id": "modified-gilbert",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fold 0 , rmse score: 0.47644676322042595\n",
            "Fold 1 , rmse score: 0.2580198076420894\n",
            "Fold 2 , rmse score: 0.252983730404579\n",
            "Fold 3 , rmse score: 0.24733055737587817\n",
            "Fold 4 , rmse score: 0.25834555465951337\n",
            "mean rmse 0.29862528266049715\n",
            "Fold 0 , rmse score: 0.2460748122083573\n",
            "Fold 1 , rmse score: 0.5002232339290128\n",
            "Fold 2 , rmse score: 0.2480781999114794\n",
            "Fold 3 , rmse score: 0.2333080739775767\n",
            "Fold 4 , rmse score: 0.25329065068250306\n",
            "mean rmse 0.29619499414178585\n",
            "Fold 0 , rmse score: 0.36769025906698505\n",
            "Fold 1 , rmse score: 0.3927829191553777\n",
            "Fold 2 , rmse score: 0.49060283623655615\n",
            "Fold 3 , rmse score: 0.36061301447392485\n",
            "Fold 4 , rmse score: 0.3846737124908605\n",
            "mean rmse 0.3992725482847409\n",
            "Fold 0 , rmse score: 0.2991491331251114\n",
            "Fold 1 , rmse score: 0.28737739716100086\n",
            "Fold 2 , rmse score: 0.29068329146673944\n",
            "Fold 3 , rmse score: 0.45421828700545724\n",
            "Fold 4 , rmse score: 0.309468799691341\n",
            "mean rmse 0.32817938168993\n",
            "Fold 0 , rmse score: 0.39531866346052036\n",
            "Fold 1 , rmse score: 0.4200360803573606\n",
            "Fold 2 , rmse score: 0.3940485952802514\n",
            "Fold 3 , rmse score: 0.3894437017666361\n",
            "Fold 4 , rmse score: 0.507282642484574\n",
            "mean rmse 0.4212259366698685\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-23T06:28:35.815058Z",
          "iopub.status.busy": "2021-06-23T06:28:35.814095Z",
          "iopub.status.idle": "2021-06-23T06:28:35.817643Z",
          "shell.execute_reply": "2021-06-23T06:28:35.817085Z",
          "shell.execute_reply.started": "2021-06-23T06:09:21.340689Z"
        },
        "papermill": {
          "duration": 0.090755,
          "end_time": "2021-06-23T06:28:35.817794",
          "exception": false,
          "start_time": "2021-06-23T06:28:35.727039",
          "status": "completed"
        },
        "tags": [],
        "id": "marked-posting"
      },
      "source": [
        "svm_preds = (svm_preds1 + svm_preds2 + svm_preds3 + svm_preds4 + svm_preds5)/5"
      ],
      "id": "marked-posting",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.084244,
          "end_time": "2021-06-23T06:28:35.986578",
          "exception": false,
          "start_time": "2021-06-23T06:28:35.902334",
          "status": "completed"
        },
        "tags": [],
        "id": "competent-silicon"
      },
      "source": [
        "## Ensemble roberta-large model"
      ],
      "id": "competent-silicon"
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-23T06:28:36.175206Z",
          "iopub.status.busy": "2021-06-23T06:28:36.174056Z",
          "iopub.status.idle": "2021-06-23T06:28:36.176786Z",
          "shell.execute_reply": "2021-06-23T06:28:36.177443Z",
          "shell.execute_reply.started": "2021-06-23T06:09:26.538028Z"
        },
        "papermill": {
          "duration": 0.107026,
          "end_time": "2021-06-23T06:28:36.177636",
          "exception": false,
          "start_time": "2021-06-23T06:28:36.070610",
          "status": "completed"
        },
        "tags": [],
        "id": "diagnostic-government"
      },
      "source": [
        "%matplotlib inline\n",
        "from glob import glob\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import json\n",
        "from collections import defaultdict\n",
        "import gc\n",
        "gc.enable()"
      ],
      "id": "diagnostic-government",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-23T06:28:36.355688Z",
          "iopub.status.busy": "2021-06-23T06:28:36.354464Z",
          "iopub.status.idle": "2021-06-23T06:28:36.360944Z",
          "shell.execute_reply": "2021-06-23T06:28:36.357487Z",
          "shell.execute_reply.started": "2021-06-23T06:09:27.632558Z"
        },
        "papermill": {
          "duration": 0.098865,
          "end_time": "2021-06-23T06:28:36.361196",
          "exception": false,
          "start_time": "2021-06-23T06:28:36.262331",
          "status": "completed"
        },
        "tags": [],
        "id": "opening-skiing"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.optim.optimizer import Optimizer\n",
        "import torch.optim.lr_scheduler as lr_scheduler\n",
        "from torch.utils.data import (\n",
        "    Dataset, DataLoader, \n",
        "    SequentialSampler, RandomSampler\n",
        ")\n",
        "from transformers import RobertaConfig\n",
        "from transformers import (\n",
        "    get_cosine_schedule_with_warmup, \n",
        "    get_cosine_with_hard_restarts_schedule_with_warmup\n",
        ")\n",
        "from transformers import RobertaTokenizer\n",
        "from transformers import RobertaModel\n",
        "from IPython.display import clear_output\n",
        "from tqdm import tqdm, trange"
      ],
      "id": "opening-skiing",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-23T06:28:36.536781Z",
          "iopub.status.busy": "2021-06-23T06:28:36.535660Z",
          "iopub.status.idle": "2021-06-23T06:28:36.539029Z",
          "shell.execute_reply": "2021-06-23T06:28:36.538437Z",
          "shell.execute_reply.started": "2021-06-23T06:09:28.810406Z"
        },
        "papermill": {
          "duration": 0.093527,
          "end_time": "2021-06-23T06:28:36.539164",
          "exception": false,
          "start_time": "2021-06-23T06:28:36.445637",
          "status": "completed"
        },
        "tags": [],
        "id": "tribal-reader"
      },
      "source": [
        "def convert_examples_to_features(data, tokenizer, max_len, is_test=False):\n",
        "    data = data.replace('\\n', '')\n",
        "    tok = tokenizer.encode_plus(\n",
        "        data, \n",
        "        max_length=max_len, \n",
        "        truncation=True,\n",
        "        return_attention_mask=True,\n",
        "        return_token_type_ids=True\n",
        "    )\n",
        "    curr_sent = {}\n",
        "    padding_length = max_len - len(tok['input_ids'])\n",
        "    curr_sent['input_ids'] = tok['input_ids'] + ([0] * padding_length)\n",
        "    curr_sent['token_type_ids'] = tok['token_type_ids'] + \\\n",
        "        ([0] * padding_length)\n",
        "    curr_sent['attention_mask'] = tok['attention_mask'] + \\\n",
        "        ([0] * padding_length)\n",
        "    return curr_sent"
      ],
      "id": "tribal-reader",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-23T06:28:36.720446Z",
          "iopub.status.busy": "2021-06-23T06:28:36.718432Z",
          "iopub.status.idle": "2021-06-23T06:28:36.721406Z",
          "shell.execute_reply": "2021-06-23T06:28:36.721960Z",
          "shell.execute_reply.started": "2021-06-23T06:09:29.976969Z"
        },
        "papermill": {
          "duration": 0.09922,
          "end_time": "2021-06-23T06:28:36.722114",
          "exception": false,
          "start_time": "2021-06-23T06:28:36.622894",
          "status": "completed"
        },
        "tags": [],
        "id": "extended-trace"
      },
      "source": [
        "class DatasetRetriever(Dataset):\n",
        "    def __init__(self, data, tokenizer, max_len, is_test=False):\n",
        "        self.data = data\n",
        "        self.excerpts = self.data.excerpt.values.tolist()\n",
        "        self.tokenizer = tokenizer\n",
        "        self.is_test = is_test\n",
        "        self.max_len = max_len\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "    \n",
        "    def __getitem__(self, item):\n",
        "        if not self.is_test:\n",
        "            excerpt, label = self.excerpts[item], self.targets[item]\n",
        "            features = convert_examples_to_features(\n",
        "                excerpt, self.tokenizer, \n",
        "                self.max_len, self.is_test\n",
        "            )\n",
        "            return {\n",
        "                'input_ids':torch.tensor(features['input_ids'], dtype=torch.long),\n",
        "                'token_type_ids':torch.tensor(features['token_type_ids'], dtype=torch.long),\n",
        "                'attention_mask':torch.tensor(features['attention_mask'], dtype=torch.long),\n",
        "                'label':torch.tensor(label, dtype=torch.double),\n",
        "            }\n",
        "        else:\n",
        "            excerpt = self.excerpts[item]\n",
        "            features = convert_examples_to_features(\n",
        "                excerpt, self.tokenizer, \n",
        "                self.max_len, self.is_test\n",
        "            )\n",
        "            return {\n",
        "                'input_ids':torch.tensor(features['input_ids'], dtype=torch.long),\n",
        "                'token_type_ids':torch.tensor(features['token_type_ids'], dtype=torch.long),\n",
        "                'attention_mask':torch.tensor(features['attention_mask'], dtype=torch.long),\n",
        "            }"
      ],
      "id": "extended-trace",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-23T06:28:36.907195Z",
          "iopub.status.busy": "2021-06-23T06:28:36.906120Z",
          "iopub.status.idle": "2021-06-23T06:28:36.908977Z",
          "shell.execute_reply": "2021-06-23T06:28:36.909559Z",
          "shell.execute_reply.started": "2021-06-23T06:09:30.852972Z"
        },
        "papermill": {
          "duration": 0.10434,
          "end_time": "2021-06-23T06:28:36.909714",
          "exception": false,
          "start_time": "2021-06-23T06:28:36.805374",
          "status": "completed"
        },
        "tags": [],
        "id": "included-restriction"
      },
      "source": [
        "class CommonLitModel(nn.Module):\n",
        "    def __init__(\n",
        "        self, \n",
        "        model_name, \n",
        "        config,  \n",
        "        multisample_dropout=False,\n",
        "        output_hidden_states=False\n",
        "    ):\n",
        "        super(CommonLitModel, self).__init__()\n",
        "        self.config = config\n",
        "        self.roberta = RobertaModel.from_pretrained(\n",
        "            model_name, \n",
        "            output_hidden_states=output_hidden_states\n",
        "        )\n",
        "        self.layer_norm = nn.LayerNorm(config.hidden_size)\n",
        "        if multisample_dropout:\n",
        "            self.dropouts = nn.ModuleList([\n",
        "                nn.Dropout(0.5) for _ in range(5)\n",
        "            ])\n",
        "        else:\n",
        "            self.dropouts = nn.ModuleList([nn.Dropout(0.3)])\n",
        "        self.regressor = nn.Linear(config.hidden_size, 1)\n",
        "        self._init_weights(self.layer_norm)\n",
        "        self._init_weights(self.regressor)\n",
        " \n",
        "    def _init_weights(self, module):\n",
        "        if isinstance(module, nn.Linear):\n",
        "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
        "            if module.bias is not None:\n",
        "                module.bias.data.zero_()\n",
        "        elif isinstance(module, nn.Embedding):\n",
        "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
        "            if module.padding_idx is not None:\n",
        "                module.weight.data[module.padding_idx].zero_()\n",
        "        elif isinstance(module, nn.LayerNorm):\n",
        "            module.bias.data.zero_()\n",
        "            module.weight.data.fill_(1.0)\n",
        " \n",
        "    def forward(\n",
        "        self, \n",
        "        input_ids=None,\n",
        "        attention_mask=None,\n",
        "        token_type_ids=None,\n",
        "        labels=None\n",
        "    ):\n",
        "        outputs = self.roberta(\n",
        "            input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            token_type_ids=token_type_ids,\n",
        "        )\n",
        "        sequence_output = outputs[1]\n",
        "        sequence_output = self.layer_norm(sequence_output)\n",
        " \n",
        "        # multi-sample dropout\n",
        "        for i, dropout in enumerate(self.dropouts):\n",
        "            if i == 0:\n",
        "                logits = self.regressor(dropout(sequence_output))\n",
        "            else:\n",
        "                logits += self.regressor(dropout(sequence_output))\n",
        "        \n",
        "        logits /= len(self.dropouts)\n",
        " \n",
        "        # calculate loss\n",
        "        loss = None\n",
        "        if labels is not None:\n",
        "            loss_fn = torch.nn.MSELoss()\n",
        "            logits = logits.view(-1).to(labels.dtype)\n",
        "            loss = torch.sqrt(loss_fn(logits, labels.view(-1)))\n",
        "        \n",
        "        output = (logits,) + outputs[1:]\n",
        "        return ((loss,) + output) if loss is not None else output"
      ],
      "id": "included-restriction",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-23T06:28:37.085364Z",
          "iopub.status.busy": "2021-06-23T06:28:37.084280Z",
          "iopub.status.idle": "2021-06-23T06:28:37.087609Z",
          "shell.execute_reply": "2021-06-23T06:28:37.087060Z",
          "shell.execute_reply.started": "2021-06-23T06:09:31.730347Z"
        },
        "papermill": {
          "duration": 0.094361,
          "end_time": "2021-06-23T06:28:37.087752",
          "exception": false,
          "start_time": "2021-06-23T06:28:36.993391",
          "status": "completed"
        },
        "tags": [],
        "id": "official-characteristic"
      },
      "source": [
        "def make_model(model_name, num_labels=1):\n",
        "    tokenizer = RobertaTokenizer.from_pretrained(model_name)\n",
        "    config = RobertaConfig.from_pretrained(model_name)\n",
        "    config.update({'num_labels':num_labels})\n",
        "    model = CommonLitModel(model_name, config=config)\n",
        "    return model, tokenizer\n",
        "\n",
        "def make_loader(\n",
        "    data, \n",
        "    tokenizer, \n",
        "    max_len,\n",
        "    batch_size,\n",
        "):\n",
        "    \n",
        "    test_dataset = DatasetRetriever(data, tokenizer, max_len, is_test=True)\n",
        "    test_sampler = SequentialSampler(test_dataset)\n",
        "    test_loader = DataLoader(\n",
        "        test_dataset, \n",
        "        batch_size=batch_size // 2, \n",
        "        sampler=test_sampler, \n",
        "        pin_memory=False, \n",
        "        drop_last=False, \n",
        "        num_workers=0\n",
        "    )\n",
        "\n",
        "    return test_loader"
      ],
      "id": "official-characteristic",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-23T06:28:37.267120Z",
          "iopub.status.busy": "2021-06-23T06:28:37.266037Z",
          "iopub.status.idle": "2021-06-23T06:28:37.269242Z",
          "shell.execute_reply": "2021-06-23T06:28:37.269762Z",
          "shell.execute_reply.started": "2021-06-23T06:09:32.556308Z"
        },
        "papermill": {
          "duration": 0.09837,
          "end_time": "2021-06-23T06:28:37.269920",
          "exception": false,
          "start_time": "2021-06-23T06:28:37.171550",
          "status": "completed"
        },
        "tags": [],
        "id": "architectural-techno"
      },
      "source": [
        "class Evaluator:\n",
        "    def __init__(self, model, scalar=None):\n",
        "        self.model = model\n",
        "        self.scalar = scalar\n",
        "\n",
        "    def evaluate(self, data_loader, tokenizer):\n",
        "        preds = []\n",
        "        self.model.eval()\n",
        "        total_loss = 0\n",
        "        with torch.no_grad():\n",
        "            for batch_idx, batch_data in enumerate(data_loader):\n",
        "                input_ids, attention_mask, token_type_ids = batch_data['input_ids'], \\\n",
        "                    batch_data['attention_mask'], batch_data['token_type_ids']\n",
        "                input_ids, attention_mask, token_type_ids = input_ids.cuda(), \\\n",
        "                    attention_mask.cuda(), token_type_ids.cuda()\n",
        "                \n",
        "                if self.scalar is not None:\n",
        "                    with torch.cuda.amp.autocast():\n",
        "                        outputs = self.model(\n",
        "                            input_ids=input_ids,\n",
        "                            attention_mask=attention_mask,\n",
        "                            token_type_ids=token_type_ids\n",
        "                        )\n",
        "                else:\n",
        "                    outputs = self.model(\n",
        "                        input_ids=input_ids,\n",
        "                        attention_mask=attention_mask,\n",
        "                        token_type_ids=token_type_ids\n",
        "                    )\n",
        "                \n",
        "                logits = outputs[0].detach().cpu().numpy().squeeze().tolist()\n",
        "                preds += logits\n",
        "        return preds"
      ],
      "id": "architectural-techno",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-23T06:28:37.447961Z",
          "iopub.status.busy": "2021-06-23T06:28:37.446965Z",
          "iopub.status.idle": "2021-06-23T06:28:37.450711Z",
          "shell.execute_reply": "2021-06-23T06:28:37.450086Z",
          "shell.execute_reply.started": "2021-06-23T06:09:33.348481Z"
        },
        "papermill": {
          "duration": 0.09573,
          "end_time": "2021-06-23T06:28:37.450861",
          "exception": false,
          "start_time": "2021-06-23T06:28:37.355131",
          "status": "completed"
        },
        "tags": [],
        "id": "behind-cisco"
      },
      "source": [
        "def config(fold, model_name, load_model_path):\n",
        "    torch.manual_seed(2021)\n",
        "    torch.cuda.manual_seed(2021)\n",
        "    torch.cuda.manual_seed_all(2021)\n",
        "    \n",
        "    max_len = 250\n",
        "    batch_size = 8\n",
        "\n",
        "    model, tokenizer = make_model(\n",
        "        model_name=model_name, \n",
        "        num_labels=1\n",
        "    )\n",
        "    model.load_state_dict(\n",
        "        torch.load(f'{load_model_path}/model{fold}.bin')\n",
        "    )\n",
        "    test_loader = make_loader(\n",
        "        test, tokenizer, max_len=max_len,\n",
        "        batch_size=batch_size\n",
        "    )\n",
        "\n",
        "    if torch.cuda.device_count() >= 1:\n",
        "        print('Model pushed to {} GPU(s), type {}.'.format(\n",
        "            torch.cuda.device_count(), \n",
        "            torch.cuda.get_device_name(0))\n",
        "        )\n",
        "        model = model.cuda() \n",
        "    else:\n",
        "        raise ValueError('CPU training is not supported')\n",
        "\n",
        "    # scaler = torch.cuda.amp.GradScaler()\n",
        "    scaler = None\n",
        "    return (\n",
        "        model, tokenizer, \n",
        "        test_loader, scaler\n",
        "    )"
      ],
      "id": "behind-cisco",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-23T06:28:37.628295Z",
          "iopub.status.busy": "2021-06-23T06:28:37.627117Z",
          "iopub.status.idle": "2021-06-23T06:28:37.630601Z",
          "shell.execute_reply": "2021-06-23T06:28:37.630024Z",
          "shell.execute_reply.started": "2021-06-23T06:09:34.084761Z"
        },
        "papermill": {
          "duration": 0.095391,
          "end_time": "2021-06-23T06:28:37.630740",
          "exception": false,
          "start_time": "2021-06-23T06:28:37.535349",
          "status": "completed"
        },
        "tags": [],
        "id": "environmental-dealing"
      },
      "source": [
        "def run(fold=0, model_name=None, load_model_path=None):\n",
        "    model, tokenizer, \\\n",
        "        test_loader, scaler = config(fold, model_name, load_model_path)\n",
        "    \n",
        "    import time\n",
        "\n",
        "    evaluator = Evaluator(model, scaler)\n",
        "\n",
        "    test_time_list = []\n",
        "\n",
        "    torch.cuda.synchronize()\n",
        "    tic1 = time.time()\n",
        "\n",
        "    preds = evaluator.evaluate(test_loader, tokenizer)\n",
        "\n",
        "    torch.cuda.synchronize()\n",
        "    tic2 = time.time() \n",
        "    test_time_list.append(tic2 - tic1)\n",
        "    \n",
        "    del model, tokenizer, test_loader, scaler\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()\n",
        "    \n",
        "    return preds"
      ],
      "id": "environmental-dealing",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-23T06:28:37.811978Z",
          "iopub.status.busy": "2021-06-23T06:28:37.810971Z",
          "iopub.status.idle": "2021-06-23T06:33:46.249362Z",
          "shell.execute_reply": "2021-06-23T06:33:46.248776Z",
          "shell.execute_reply.started": "2021-06-23T06:17:38.888821Z"
        },
        "papermill": {
          "duration": 308.532737,
          "end_time": "2021-06-23T06:33:46.249537",
          "exception": false,
          "start_time": "2021-06-23T06:28:37.716800",
          "status": "completed"
        },
        "tags": [],
        "id": "circular-violation",
        "outputId": "4214afe3-18f9-405c-9032-0cfe51facdb8"
      },
      "source": [
        "%%time\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "train = pd.read_csv('../input/commonlitreadabilityprize/train.csv')\n",
        "test = pd.read_csv('../input/commonlitreadabilityprize/test.csv')\n",
        "\n",
        "pred_df1 = pd.DataFrame()\n",
        "pred_df2 = pd.DataFrame()\n",
        "pred_df3 = pd.DataFrame()\n",
        "for fold in tqdm(range(5)):\n",
        "    pred_df1[f'fold{fold}'] = run(fold, '../input/roberta-base/', '../input/commonlit-roberta-base-i/')\n",
        "    pred_df2[f'fold{fold+5}'] = run(fold, '../input/robertalarge/', '../input/roberta-large-itptfit/')\n",
        "    pred_df3[f'fold{fold+10}'] = run(fold, '../input/robertalarge/', '../input/commonlit-roberta-large-ii/')"
      ],
      "id": "circular-violation",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 0/5 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model pushed to 1 GPU(s), type Tesla P100-PCIE-16GB.\n",
            "Model pushed to 1 GPU(s), type Tesla P100-PCIE-16GB.\n",
            "Model pushed to 1 GPU(s), type Tesla P100-PCIE-16GB.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 20%|        | 1/5 [01:09<04:39, 69.96s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model pushed to 1 GPU(s), type Tesla P100-PCIE-16GB.\n",
            "Model pushed to 1 GPU(s), type Tesla P100-PCIE-16GB.\n",
            "Model pushed to 1 GPU(s), type Tesla P100-PCIE-16GB.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 40%|      | 2/5 [02:09<03:11, 63.92s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model pushed to 1 GPU(s), type Tesla P100-PCIE-16GB.\n",
            "Model pushed to 1 GPU(s), type Tesla P100-PCIE-16GB.\n",
            "Model pushed to 1 GPU(s), type Tesla P100-PCIE-16GB.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 60%|    | 3/5 [03:09<02:04, 62.15s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model pushed to 1 GPU(s), type Tesla P100-PCIE-16GB.\n",
            "Model pushed to 1 GPU(s), type Tesla P100-PCIE-16GB.\n",
            "Model pushed to 1 GPU(s), type Tesla P100-PCIE-16GB.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 80%|  | 4/5 [04:10<01:01, 61.74s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model pushed to 1 GPU(s), type Tesla P100-PCIE-16GB.\n",
            "Model pushed to 1 GPU(s), type Tesla P100-PCIE-16GB.\n",
            "Model pushed to 1 GPU(s), type Tesla P100-PCIE-16GB.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|| 5/5 [05:08<00:00, 61.68s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 1min 57s, sys: 26.5 s, total: 2min 23s\n",
            "Wall time: 5min 8s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-23T06:33:46.443147Z",
          "iopub.status.busy": "2021-06-23T06:33:46.442154Z",
          "iopub.status.idle": "2021-06-23T06:33:47.537118Z",
          "shell.execute_reply": "2021-06-23T06:33:47.537775Z",
          "shell.execute_reply.started": "2021-06-23T06:23:23.029048Z"
        },
        "papermill": {
          "duration": 1.196692,
          "end_time": "2021-06-23T06:33:47.537955",
          "exception": false,
          "start_time": "2021-06-23T06:33:46.341263",
          "status": "completed"
        },
        "tags": [],
        "id": "three-strategy"
      },
      "source": [
        "sample['target'] = (pred_df2.mean(axis=1)*0.35) + (pred_df1.mean(axis=1)*0.20) + (pred_df3.mean(axis=1) * 0.15) + (svm_preds * 0.30)\n",
        "sample.to_csv('submission.csv', index=False)"
      ],
      "id": "three-strategy",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-23T06:33:47.736970Z",
          "iopub.status.busy": "2021-06-23T06:33:47.736154Z",
          "iopub.status.idle": "2021-06-23T06:33:47.747362Z",
          "shell.execute_reply": "2021-06-23T06:33:47.747911Z",
          "shell.execute_reply.started": "2021-06-23T06:23:26.579181Z"
        },
        "papermill": {
          "duration": 0.117198,
          "end_time": "2021-06-23T06:33:47.748071",
          "exception": false,
          "start_time": "2021-06-23T06:33:47.630873",
          "status": "completed"
        },
        "tags": [],
        "id": "played-checkout",
        "outputId": "2aecf1eb-7a9f-4a95-b0fc-0932c683647a"
      },
      "source": [
        "sample"
      ],
      "id": "played-checkout",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>c0f722661</td>\n",
              "      <td>-0.446686</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>f0953f0a5</td>\n",
              "      <td>-0.562361</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0df072751</td>\n",
              "      <td>-0.462597</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>04caf4e0c</td>\n",
              "      <td>-2.404289</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0e63f8bea</td>\n",
              "      <td>-1.862155</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>12537fe78</td>\n",
              "      <td>-1.181580</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>965e592c0</td>\n",
              "      <td>0.202756</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          id    target\n",
              "0  c0f722661 -0.446686\n",
              "1  f0953f0a5 -0.562361\n",
              "2  0df072751 -0.462597\n",
              "3  04caf4e0c -2.404289\n",
              "4  0e63f8bea -1.862155\n",
              "5  12537fe78 -1.181580\n",
              "6  965e592c0  0.202756"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    }
  ]
}