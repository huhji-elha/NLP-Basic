{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 2518.333221,
      "end_time": "2021-06-15T12:15:23.291012",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2021-06-15T11:33:24.957791",
      "version": "2.3.3"
    },
    "colab": {
      "name": "Transformer_basic.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b9a723a3063b40109557ff3f09749369": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "state": {
            "_view_name": "VBoxView",
            "_dom_classes": [],
            "_model_name": "VBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_d0078dafb40a46dfb014002788f63064",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_369737af0a5149edb903a68a86c21fee",
              "IPY_MODEL_e22c0d32c5ca476c876e4aacc3adcf47"
            ]
          }
        },
        "d0078dafb40a46dfb014002788f63064": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "369737af0a5149edb903a68a86c21fee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "state": {
            "_view_name": "LabelView",
            "style": "IPY_MODEL_b0f595e7101f4969914b9446eb682b13",
            "_dom_classes": [],
            "description": "",
            "_model_name": "LabelModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0.01MB of 0.01MB uploaded (0.00MB deduped)\r",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5add327861344fd2bc6e6f20e654d9ca"
          }
        },
        "e22c0d32c5ca476c876e4aacc3adcf47": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_182f11ddd2504dde8daffc8413e3458e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3fe4ef9d2bed427fa225d56197d81f6d"
          }
        },
        "b0f595e7101f4969914b9446eb682b13": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5add327861344fd2bc6e6f20e654d9ca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "182f11ddd2504dde8daffc8413e3458e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3fe4ef9d2bed427fa225d56197d81f6d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/huhji/NLP-Basic/blob/main/Transformer_basic.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FCA8XXk39eCi"
      },
      "source": [
        "# Transformer & roBERTa Basic"
      ],
      "id": "FCA8XXk39eCi"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j1uq7-kt9KtW"
      },
      "source": [
        "## Import Libraries"
      ],
      "id": "j1uq7-kt9KtW"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t2mT-4p8-DHp"
      },
      "source": [
        "!pip install transformers\n",
        "!pip install wandb"
      ],
      "id": "t2mT-4p8-DHp",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-15T11:33:31.620636Z",
          "iopub.status.busy": "2021-06-15T11:33:31.619984Z",
          "iopub.status.idle": "2021-06-15T11:33:37.588397Z",
          "shell.execute_reply": "2021-06-15T11:33:37.587474Z",
          "shell.execute_reply.started": "2021-06-15T11:20:19.660143Z"
        },
        "papermill": {
          "duration": 5.991588,
          "end_time": "2021-06-15T11:33:37.588597",
          "exception": false,
          "start_time": "2021-06-15T11:33:31.597009",
          "status": "completed"
        },
        "tags": [],
        "id": "negative-transport"
      },
      "source": [
        "import os\n",
        "import random\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import wandb\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import get_cosine_schedule_with_warmup\n",
        "from transformers import (AutoModel,AutoModelForMaskedLM, AutoTokenizer, LineByLineTextDataset,\n",
        "                         DataCollatorForLanguageModeling,Trainer, TrainingArguments,)"
      ],
      "id": "negative-transport",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C6jdGLQp9-Ro"
      },
      "source": [
        "## Load Data"
      ],
      "id": "C6jdGLQp9-Ro"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y0pYqi8w95ox",
        "outputId": "2fc6c936-0a2e-4455-9b82-e3b687fa53e4"
      },
      "source": [
        "# Google Drive에서 업로드\n",
        "from google.colab import drive \n",
        "drive.mount('/content/gdrive/')"
      ],
      "id": "y0pYqi8w95ox",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-15T11:33:38.862919Z",
          "iopub.status.busy": "2021-06-15T11:33:38.862381Z",
          "iopub.status.idle": "2021-06-15T11:33:38.942215Z",
          "shell.execute_reply": "2021-06-15T11:33:38.941314Z",
          "shell.execute_reply.started": "2021-06-15T11:20:35.345697Z"
        },
        "papermill": {
          "duration": 0.105266,
          "end_time": "2021-06-15T11:33:38.942404",
          "exception": false,
          "start_time": "2021-06-15T11:33:38.837138",
          "status": "completed"
        },
        "tags": [],
        "id": "sublime-computer"
      },
      "source": [
        "#os.getcwd()\n",
        "data_path = \"./gdrive/MyDrive/Kaggle_CommonLit\"\n",
        "\n",
        "train_data = pd.read_csv(os.path.join(data_path,\"train.csv\"))\n",
        "test_data = pd.read_csv(os.path.join(data_path, \"test.csv\"))\n",
        "sample_sub = pd.read_csv(os.path.join(data_path, \"sample_submission.csv\"))"
      ],
      "id": "sublime-computer",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-15T11:33:38.999288Z",
          "iopub.status.busy": "2021-06-15T11:33:38.998449Z",
          "iopub.status.idle": "2021-06-15T11:33:39.003416Z",
          "shell.execute_reply": "2021-06-15T11:33:39.002971Z",
          "shell.execute_reply.started": "2021-06-15T11:20:37.557911Z"
        },
        "papermill": {
          "duration": 0.040713,
          "end_time": "2021-06-15T11:33:39.003533",
          "exception": false,
          "start_time": "2021-06-15T11:33:38.962820",
          "status": "completed"
        },
        "tags": [],
        "id": "abroad-anchor"
      },
      "source": [
        "text  = '.'.join(train_data.excerpt.tolist() + test_data.excerpt.tolist())\n",
        "\n",
        "with open(os.path.join(data_path,'text.txt'),'w') as f:\n",
        "    f.write(text)"
      ],
      "id": "abroad-anchor",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BVdlhNqj-jXt"
      },
      "source": [
        "## Load pretrained roBERTa"
      ],
      "id": "BVdlhNqj-jXt"
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-15T11:33:39.046242Z",
          "iopub.status.busy": "2021-06-15T11:33:39.045767Z",
          "iopub.status.idle": "2021-06-15T11:33:50.423646Z",
          "shell.execute_reply": "2021-06-15T11:33:50.423084Z",
          "shell.execute_reply.started": "2021-06-15T11:26:44.397003Z"
        },
        "papermill": {
          "duration": 11.400373,
          "end_time": "2021-06-15T11:33:50.423790",
          "exception": false,
          "start_time": "2021-06-15T11:33:39.023417",
          "status": "completed"
        },
        "tags": [],
        "id": "scientific-terminal"
      },
      "source": [
        "model_name = 'roberta-base'\n",
        "model =  AutoModelForMaskedLM.from_pretrained(model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)"
      ],
      "id": "scientific-terminal",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-15T11:33:50.471097Z",
          "iopub.status.busy": "2021-06-15T11:33:50.470257Z",
          "iopub.status.idle": "2021-06-15T11:33:59.119681Z",
          "shell.execute_reply": "2021-06-15T11:33:59.119151Z",
          "shell.execute_reply.started": "2021-06-15T11:26:54.364391Z"
        },
        "papermill": {
          "duration": 8.675325,
          "end_time": "2021-06-15T11:33:59.119825",
          "exception": false,
          "start_time": "2021-06-15T11:33:50.444500",
          "status": "completed"
        },
        "tags": [],
        "id": "digital-preference"
      },
      "source": [
        "dataset = LineByLineTextDataset(\n",
        "    tokenizer=tokenizer,\n",
        "    file_path=os.path.join(data_path,\"text.txt\"), #mention text file here\n",
        "    block_size=64,\n",
        ")\n",
        "\n",
        "data_collator = DataCollatorForLanguageModeling(\n",
        "    tokenizer=tokenizer, mlm=True, mlm_probability=0.15\n",
        ")\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir= os.path.join(data_path, \"./clrp_roberta_base_chk\"), #select model path\n",
        "    overwrite_output_dir=True,\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=64,\n",
        "    eval_steps=20,\n",
        "    metric_for_best_model = 'eval_loss',\n",
        "    greater_is_better=False,\n",
        "    load_best_model_at_end =True,\n",
        "    prediction_loss_only=True,\n",
        "    report_to = \"none\" \n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    data_collator=data_collator,\n",
        "    train_dataset=dataset)"
      ],
      "id": "digital-preference",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-15T11:33:59.312867Z",
          "iopub.status.busy": "2021-06-15T11:33:59.312247Z",
          "iopub.status.idle": "2021-06-15T11:37:48.983058Z",
          "shell.execute_reply": "2021-06-15T11:37:48.982210Z",
          "shell.execute_reply.started": "2021-06-15T11:26:59.692238Z"
        },
        "papermill": {
          "duration": 229.843396,
          "end_time": "2021-06-15T11:37:48.983205",
          "exception": false,
          "start_time": "2021-06-15T11:33:59.139809",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 114
        },
        "id": "incomplete-circulation",
        "outputId": "b9f9aedd-8cf3-4ee1-af4e-7c0e8cde4a1e"
      },
      "source": [
        "trainer.train()"
      ],
      "id": "incomplete-circulation",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='201' max='201' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [201/201 07:11, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=201, training_loss=1.8009212361046332, metrics={'train_runtime': 433.9027, 'train_samples_per_second': 0.463, 'total_flos': 614253569481216.0, 'epoch': 3.0, 'init_mem_cpu_alloc_delta': 4096, 'init_mem_gpu_alloc_delta': 0, 'init_mem_cpu_peaked_delta': 0, 'init_mem_gpu_peaked_delta': 0, 'train_mem_cpu_alloc_delta': 102400, 'train_mem_gpu_alloc_delta': 1041950208, 'train_mem_cpu_peaked_delta': 0, 'train_mem_gpu_peaked_delta': 6346656768})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-15T11:37:49.028635Z",
          "iopub.status.busy": "2021-06-15T11:37:49.027890Z",
          "iopub.status.idle": "2021-06-15T11:37:50.546127Z",
          "shell.execute_reply": "2021-06-15T11:37:50.545649Z",
          "shell.execute_reply.started": "2021-06-15T11:32:26.518725Z"
        },
        "papermill": {
          "duration": 1.542405,
          "end_time": "2021-06-15T11:37:50.546263",
          "exception": false,
          "start_time": "2021-06-15T11:37:49.003858",
          "status": "completed"
        },
        "tags": [],
        "id": "sophisticated-equilibrium"
      },
      "source": [
        "trainer.save_model(os.path.join(data_path, \"/clrp_roberta_base_chk\"))"
      ],
      "id": "sophisticated-equilibrium",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-15T11:37:50.618130Z",
          "iopub.status.busy": "2021-06-15T11:37:50.617400Z",
          "iopub.status.idle": "2021-06-15T11:37:50.621807Z",
          "shell.execute_reply": "2021-06-15T11:37:50.622379Z",
          "shell.execute_reply.started": "2021-06-15T11:32:30.011117Z"
        },
        "papermill": {
          "duration": 0.043631,
          "end_time": "2021-06-15T11:37:50.622555",
          "exception": false,
          "start_time": "2021-06-15T11:37:50.578924",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "blond-revelation",
        "outputId": "8ec0538a-3200-4670-8fb2-e7afe6963088"
      },
      "source": [
        "os.listdir(os.path.join(data_path, '/clrp_roberta_base_chk'))"
      ],
      "id": "blond-revelation",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['config.json', 'pytorch_model.bin', 'training_args.bin']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VDley-cyD6LZ",
        "outputId": "bc7f7fb1-36cc-4bb6-bbf4-4836a268f8be"
      },
      "source": [
        "import glob\n",
        "glob.glob(data_path + \"/*\")"
      ],
      "id": "VDley-cyD6LZ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['./gdrive/MyDrive/Kaggle_CommonLit/sample_submission.csv',\n",
              " './gdrive/MyDrive/Kaggle_CommonLit/train.csv',\n",
              " './gdrive/MyDrive/Kaggle_CommonLit/test.csv',\n",
              " './gdrive/MyDrive/Kaggle_CommonLit/cleaned_train.csv',\n",
              " './gdrive/MyDrive/Kaggle_CommonLit/cleaned_test.csv',\n",
              " './gdrive/MyDrive/Kaggle_CommonLit/text.txt',\n",
              " './gdrive/MyDrive/Kaggle_CommonLit/clrp_roberta_base_chk',\n",
              " './gdrive/MyDrive/Kaggle_CommonLit/Transformer_basic.ipynb']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-15T11:37:50.696583Z",
          "iopub.status.busy": "2021-06-15T11:37:50.695811Z",
          "iopub.status.idle": "2021-06-15T11:37:50.703858Z",
          "shell.execute_reply": "2021-06-15T11:37:50.704796Z",
          "shell.execute_reply.started": "2021-06-15T11:32:37.034422Z"
        },
        "papermill": {
          "duration": 0.049387,
          "end_time": "2021-06-15T11:37:50.704961",
          "exception": false,
          "start_time": "2021-06-15T11:37:50.655574",
          "status": "completed"
        },
        "tags": [],
        "id": "selected-arrival"
      },
      "source": [
        "num_bins = int(np.floor(1 + np.log2(len(train_data))))\n",
        "train_data.loc[:,'bins'] = pd.cut(train_data['target'],bins=num_bins,labels=False)\n",
        "\n",
        "bins = train_data.bins.to_numpy()\n",
        "target = train_data.target.to_numpy()\n",
        "\n",
        "def rmse_score(y_true,y_pred):\n",
        "    return np.sqrt(mean_squared_error(y_true,y_pred))"
      ],
      "id": "selected-arrival",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        },
        "id": "1O9o3_UfFUYL",
        "outputId": "9f5bb581-293d-4dcb-d75f-651e640ee5bd"
      },
      "source": [
        "train_data"
      ],
      "id": "1O9o3_UfFUYL",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>url_legal</th>\n",
              "      <th>license</th>\n",
              "      <th>excerpt</th>\n",
              "      <th>target</th>\n",
              "      <th>standard_error</th>\n",
              "      <th>bins</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>c12129c31</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>When the young people returned to the ballroom...</td>\n",
              "      <td>-0.340259</td>\n",
              "      <td>0.464009</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>85aa80a4c</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>All through dinner time, Mrs. Fayre was somewh...</td>\n",
              "      <td>-0.315372</td>\n",
              "      <td>0.480805</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>b69ac6792</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>As Roger had predicted, the snow departed as q...</td>\n",
              "      <td>-0.580118</td>\n",
              "      <td>0.476676</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>dd1000b26</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>And outside before the palace a great garden w...</td>\n",
              "      <td>-1.054013</td>\n",
              "      <td>0.450007</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>37c1b32fb</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Once upon a time there were Three Bears who li...</td>\n",
              "      <td>0.247197</td>\n",
              "      <td>0.510845</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2829</th>\n",
              "      <td>25ca8f498</td>\n",
              "      <td>https://sites.ehe.osu.edu/beyondpenguins/files...</td>\n",
              "      <td>CC BY-SA 3.0</td>\n",
              "      <td>When you think of dinosaurs and where they liv...</td>\n",
              "      <td>1.711390</td>\n",
              "      <td>0.646900</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2830</th>\n",
              "      <td>2c26db523</td>\n",
              "      <td>https://en.wikibooks.org/wiki/Wikijunior:The_E...</td>\n",
              "      <td>CC BY-SA 3.0</td>\n",
              "      <td>So what is a solid? Solids are usually hard be...</td>\n",
              "      <td>0.189476</td>\n",
              "      <td>0.535648</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2831</th>\n",
              "      <td>cd19e2350</td>\n",
              "      <td>https://en.wikibooks.org/wiki/Wikijunior:The_E...</td>\n",
              "      <td>CC BY-SA 3.0</td>\n",
              "      <td>The second state of matter we will discuss is ...</td>\n",
              "      <td>0.255209</td>\n",
              "      <td>0.483866</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2832</th>\n",
              "      <td>15e2e9e7a</td>\n",
              "      <td>https://en.wikibooks.org/wiki/Geometry_for_Ele...</td>\n",
              "      <td>CC BY-SA 3.0</td>\n",
              "      <td>Solids are shapes that you can actually touch....</td>\n",
              "      <td>-0.215279</td>\n",
              "      <td>0.514128</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2833</th>\n",
              "      <td>5b990ba77</td>\n",
              "      <td>https://en.wikibooks.org/wiki/Wikijunior:Biolo...</td>\n",
              "      <td>CC BY-SA 3.0</td>\n",
              "      <td>Animals are made of many cells. They eat thing...</td>\n",
              "      <td>0.300779</td>\n",
              "      <td>0.512379</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2834 rows × 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "             id  ... bins\n",
              "0     c12129c31  ...    7\n",
              "1     85aa80a4c  ...    7\n",
              "2     b69ac6792  ...    6\n",
              "3     dd1000b26  ...    5\n",
              "4     37c1b32fb  ...    8\n",
              "...         ...  ...  ...\n",
              "2829  25ca8f498  ...   11\n",
              "2830  2c26db523  ...    8\n",
              "2831  cd19e2350  ...    8\n",
              "2832  15e2e9e7a  ...    7\n",
              "2833  5b990ba77  ...    8\n",
              "\n",
              "[2834 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UnIG857MG1Np"
      },
      "source": [
        "## K-fold"
      ],
      "id": "UnIG857MG1Np"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309,
          "referenced_widgets": [
            "b9a723a3063b40109557ff3f09749369",
            "d0078dafb40a46dfb014002788f63064",
            "369737af0a5149edb903a68a86c21fee",
            "e22c0d32c5ca476c876e4aacc3adcf47",
            "b0f595e7101f4969914b9446eb682b13",
            "5add327861344fd2bc6e6f20e654d9ca",
            "182f11ddd2504dde8daffc8413e3458e",
            "3fe4ef9d2bed427fa225d56197d81f6d"
          ]
        },
        "id": "R1xCS0sXTxaF",
        "outputId": "2a44779b-cb10-4c6f-95e5-542f8ed57a18"
      },
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "wandb.init(\n",
        "  project=\"roBERTa_01\",\n",
        "  config = {\n",
        "      'lr': 2e-5,\n",
        "      'wd':0.01,\n",
        "      'batch_size':16,\n",
        "      'valid_step':10,\n",
        "      'max_len':256,\n",
        "      'epochs':3,\n",
        "      'nfolds':5,\n",
        "      'seed':42,\n",
        "  })\n",
        "config=wandb.config\n",
        "\n",
        "for i in range(config['nfolds']):\n",
        "    os.makedirs(f'model{i}',exist_ok=True)\n",
        "\n",
        "def seed_everything(seed=42):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONASSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "\n",
        "seed_everything(seed=config['seed'])\n",
        "\n",
        "train_data['Fold'] = -1\n",
        "kfold = StratifiedKFold(n_splits=config['nfolds'],shuffle=True,random_state=config['seed'])\n",
        "for k , (train_idx,valid_idx) in enumerate(kfold.split(X=train_data,y=bins)):\n",
        "    train_data.loc[valid_idx,'Fold'] = k"
      ],
      "id": "R1xCS0sXTxaF",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Finishing last run (ID:1mwvzz6w) before initializing another..."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<br/>Waiting for W&B process to finish, PID 2529<br/>Program ended successfully."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b9a723a3063b40109557ff3f09749369",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Find user logs for this run at: <code>/content/wandb/run-20210616_144938-1mwvzz6w/logs/debug.log</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Find internal logs for this run at: <code>/content/wandb/run-20210616_144938-1mwvzz6w/logs/debug-internal.log</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                    <br/>Synced <strong style=\"color:#cdcd00\">happy-galaxy-2</strong>: <a href=\"https://wandb.ai/jhhuh/roBERTa_01/runs/1mwvzz6w\" target=\"_blank\">https://wandb.ai/jhhuh/roBERTa_01/runs/1mwvzz6w</a><br/>\n",
              "                "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "...Successfully finished last run (ID:1mwvzz6w). Initializing new run:<br/><br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Tracking run with wandb version 0.10.32<br/>\n",
              "                Syncing run <strong style=\"color:#cdcd00\">floral-dust-3</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://wandb.ai/jhhuh/roBERTa_01\" target=\"_blank\">https://wandb.ai/jhhuh/roBERTa_01</a><br/>\n",
              "                Run page: <a href=\"https://wandb.ai/jhhuh/roBERTa_01/runs/8pwj9a8x\" target=\"_blank\">https://wandb.ai/jhhuh/roBERTa_01/runs/8pwj9a8x</a><br/>\n",
              "                Run data is saved locally in <code>/content/wandb/run-20210616_145359-8pwj9a8x</code><br/><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-15T11:37:50.888062Z",
          "iopub.status.busy": "2021-06-15T11:37:50.881965Z",
          "iopub.status.idle": "2021-06-15T11:37:50.899050Z",
          "shell.execute_reply": "2021-06-15T11:37:50.899975Z",
          "shell.execute_reply.started": "2021-06-15T11:32:38.370508Z"
        },
        "papermill": {
          "duration": 0.055944,
          "end_time": "2021-06-15T11:37:50.900134",
          "exception": false,
          "start_time": "2021-06-15T11:37:50.844190",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "suffering-direction",
        "outputId": "32f9e84f-9810-4015-82de-9b4b688840ab"
      },
      "source": [
        "train_data.head()"
      ],
      "id": "suffering-direction",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>url_legal</th>\n",
              "      <th>license</th>\n",
              "      <th>excerpt</th>\n",
              "      <th>target</th>\n",
              "      <th>standard_error</th>\n",
              "      <th>bins</th>\n",
              "      <th>Fold</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>c12129c31</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>When the young people returned to the ballroom...</td>\n",
              "      <td>-0.340259</td>\n",
              "      <td>0.464009</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>85aa80a4c</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>All through dinner time, Mrs. Fayre was somewh...</td>\n",
              "      <td>-0.315372</td>\n",
              "      <td>0.480805</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>b69ac6792</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>As Roger had predicted, the snow departed as q...</td>\n",
              "      <td>-0.580118</td>\n",
              "      <td>0.476676</td>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>dd1000b26</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>And outside before the palace a great garden w...</td>\n",
              "      <td>-1.054013</td>\n",
              "      <td>0.450007</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>37c1b32fb</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Once upon a time there were Three Bears who li...</td>\n",
              "      <td>0.247197</td>\n",
              "      <td>0.510845</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          id url_legal license  ... standard_error  bins  Fold\n",
              "0  c12129c31       NaN     NaN  ...       0.464009     7     0\n",
              "1  85aa80a4c       NaN     NaN  ...       0.480805     7     2\n",
              "2  b69ac6792       NaN     NaN  ...       0.476676     6     3\n",
              "3  dd1000b26       NaN     NaN  ...       0.450007     5     2\n",
              "4  37c1b32fb       NaN     NaN  ...       0.510845     8     1\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-15T11:37:50.976096Z",
          "iopub.status.busy": "2021-06-15T11:37:50.975380Z",
          "iopub.status.idle": "2021-06-15T11:37:50.978470Z",
          "shell.execute_reply": "2021-06-15T11:37:50.979021Z",
          "shell.execute_reply.started": "2021-06-15T11:32:39.485296Z"
        },
        "papermill": {
          "duration": 0.044863,
          "end_time": "2021-06-15T11:37:50.979178",
          "exception": false,
          "start_time": "2021-06-15T11:37:50.934315",
          "status": "completed"
        },
        "tags": [],
        "id": "wanted-claim"
      },
      "source": [
        "class CLRPDataset(Dataset):\n",
        "    def __init__(self,df,tokenizer,max_len=128):\n",
        "        self.excerpt = df['excerpt'].to_numpy()\n",
        "        self.targets = df['target'].to_numpy()\n",
        "        self.max_len = max_len\n",
        "        self.tokenizer = tokenizer\n",
        "    \n",
        "    def __getitem__(self,idx):\n",
        "        encode = self.tokenizer(self.excerpt[idx],\n",
        "                                return_tensors='pt',\n",
        "                                max_length=self.max_len,\n",
        "                                padding='max_length',\n",
        "                                truncation=True)\n",
        "        \n",
        "        target = torch.tensor(self.targets[idx],dtype=torch.float) \n",
        "        return encode, target\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.excerpt)"
      ],
      "id": "wanted-claim",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-15T11:37:51.055695Z",
          "iopub.status.busy": "2021-06-15T11:37:51.054888Z",
          "iopub.status.idle": "2021-06-15T11:37:51.058111Z",
          "shell.execute_reply": "2021-06-15T11:37:51.057731Z",
          "shell.execute_reply.started": "2021-06-15T11:32:40.331476Z"
        },
        "papermill": {
          "duration": 0.045232,
          "end_time": "2021-06-15T11:37:51.058210",
          "exception": false,
          "start_time": "2021-06-15T11:37:51.012978",
          "status": "completed"
        },
        "tags": [],
        "id": "handled-messenger"
      },
      "source": [
        "class AttentionHead(nn.Module):\n",
        "    def __init__(self, in_features, hidden_dim, num_targets):\n",
        "        super().__init__()\n",
        "        self.in_features = in_features\n",
        "        self.middle_features = hidden_dim\n",
        "\n",
        "        self.W = nn.Linear(in_features, hidden_dim)\n",
        "        self.V = nn.Linear(hidden_dim, 1)\n",
        "        self.out_features = hidden_dim\n",
        "\n",
        "    def forward(self, features):\n",
        "        att = torch.tanh(self.W(features))\n",
        "\n",
        "        score = self.V(att)\n",
        "\n",
        "        attention_weights = torch.softmax(score, dim=1)\n",
        "\n",
        "        context_vector = attention_weights * features\n",
        "        context_vector = torch.sum(context_vector, dim=1)\n",
        "\n",
        "        return context_vector"
      ],
      "id": "handled-messenger",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-15T11:37:51.106258Z",
          "iopub.status.busy": "2021-06-15T11:37:51.105098Z",
          "iopub.status.idle": "2021-06-15T11:37:51.107380Z",
          "shell.execute_reply": "2021-06-15T11:37:51.107775Z",
          "shell.execute_reply.started": "2021-06-15T11:32:40.897800Z"
        },
        "papermill": {
          "duration": 0.028779,
          "end_time": "2021-06-15T11:37:51.107895",
          "exception": false,
          "start_time": "2021-06-15T11:37:51.079116",
          "status": "completed"
        },
        "tags": [],
        "id": "geological-polish"
      },
      "source": [
        "class Model(nn.Module):\n",
        "    def __init__(self,path):\n",
        "        super(Model,self).__init__()\n",
        "        self.roberta = AutoModel.from_pretrained(path)  \n",
        "        self.head = AttentionHead(768,768,1)\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self.linear = nn.Linear(768,1)\n",
        "\n",
        "    def forward(self,**xb):\n",
        "        x = self.roberta(**xb)[0]\n",
        "        x = self.head(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.linear(x)\n",
        "        return x"
      ],
      "id": "geological-polish",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-15T11:37:51.165918Z",
          "iopub.status.busy": "2021-06-15T11:37:51.157513Z",
          "iopub.status.idle": "2021-06-15T11:37:51.168523Z",
          "shell.execute_reply": "2021-06-15T11:37:51.168075Z",
          "shell.execute_reply.started": "2021-06-15T11:32:41.462262Z"
        },
        "papermill": {
          "duration": 0.039929,
          "end_time": "2021-06-15T11:37:51.168619",
          "exception": false,
          "start_time": "2021-06-15T11:37:51.128690",
          "status": "completed"
        },
        "tags": [],
        "id": "injured-anderson"
      },
      "source": [
        "def run(fold,verbose=True):\n",
        "    \n",
        "    def loss_fn(outputs,targets):\n",
        "        outputs = outputs.view(-1)\n",
        "        targets = targets.view(-1)\n",
        "        return torch.sqrt(nn.MSELoss()(outputs,targets))\n",
        "    \n",
        "    def train_and_evaluate_loop(train_loader,valid_loader,model, loss_fn, device,optimizer,epoch,fold,best_loss,valid_step=10,lr_scheduler=None):\n",
        "        train_loss = 0\n",
        "        for i, (inputs1,targets1) in enumerate(train_loader):\n",
        "            model.train()\n",
        "            optimizer.zero_grad()\n",
        "            inputs1 = {key:val.reshape(val.shape[0],-1).to(device) for key,val in inputs1.items()}\n",
        "            targets1 = targets1.to(device)\n",
        "            outputs1 = model(**inputs1)\n",
        "            loss1 = loss_fn(outputs1,targets1)\n",
        "            loss1.backward()\n",
        "            optimizer.step()\n",
        "            \n",
        "            train_loss += loss1.item()\n",
        "            \n",
        "            if lr_scheduler:\n",
        "                lr_scheduler.step()\n",
        "            \n",
        "            #evaluating for every valid_step\n",
        "            if (i % valid_step == 0) or (i == (len(train_loader)-1)):\n",
        "                model.eval()\n",
        "                valid_loss = 0\n",
        "                with torch.no_grad():\n",
        "                    for j, (inputs2,targets2) in enumerate(valid_loader):\n",
        "                        inputs2 = {key:val.reshape(val.shape[0],-1).to(device) for key,val in inputs2.items()}\n",
        "                        targets2 = targets2.to(device)\n",
        "                        outputs2 = model(**inputs2)\n",
        "                        loss2 = loss_fn(outputs2,targets2)\n",
        "                        valid_loss += loss2.item()\n",
        "                     \n",
        "                    valid_loss /= len(valid_loader)\n",
        "                    if valid_loss <= best_loss:\n",
        "                        if verbose:\n",
        "                            print(f\"epoch:{epoch} | Train Loss:{train_loss/(i+1)} | Validation loss:{valid_loss}\")\n",
        "#                             print(f\"{g_}Validation loss Decreased from {best_loss} to {valid_loss}{sr_}\")\n",
        "                            print(f\"Validation loss Decreased from {best_loss} to {valid_loss}\")\n",
        "\n",
        "                        best_loss = valid_loss\n",
        "                        torch.save(model.state_dict(),f'./model{fold}/model{fold}.bin')\n",
        "                        tokenizer.save_pretrained(f'./model{fold}')\n",
        "                        \n",
        "        return best_loss\n",
        "    \n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    x_train,x_valid = train_data.query(f\"Fold != {fold}\"),train_data.query(f\"Fold == {fold}\")\n",
        "\n",
        "    MODEL_PATH = os.path.join(data_path, \"/clrp_roberta_base_chk\")\n",
        "    tokenizer = AutoTokenizer.from_pretrained('roberta-base')\n",
        "    model = Model(MODEL_PATH)\n",
        "    model.to(device)\n",
        "\n",
        "    train_ds = CLRPDataset(x_train,tokenizer,config['max_len'])\n",
        "    train_dl = DataLoader(train_ds,\n",
        "                        batch_size = config[\"batch_size\"],\n",
        "                        shuffle=True,\n",
        "                        num_workers = 4,\n",
        "                        pin_memory=True,\n",
        "                        drop_last=False)\n",
        "\n",
        "    valid_ds = CLRPDataset(x_valid,tokenizer,config['max_len'])\n",
        "    valid_dl = DataLoader(valid_ds,\n",
        "                        batch_size = config[\"batch_size\"],\n",
        "                        shuffle=False,\n",
        "                        num_workers = 4,\n",
        "                        pin_memory=True,\n",
        "                        drop_last=False)\n",
        "\n",
        "    optimizer = optim.AdamW(model.parameters(),lr=config['lr'],weight_decay=config['wd'])\n",
        "\n",
        "    lr_scheduler = get_cosine_schedule_with_warmup(optimizer,num_warmup_steps=0,num_training_steps= 10 * len(train_dl))\n",
        "\n",
        "    print(f\"Fold: {fold}\")\n",
        "    best_loss = 9999\n",
        "    for epoch in range(config[\"epochs\"]):\n",
        "        print(f\"Epoch Started:{epoch}\")\n",
        "        best_loss = train_and_evaluate_loop(train_dl,valid_dl,model,loss_fn,\n",
        "                                            device,optimizer,epoch,fold,best_loss,\n",
        "                                            valid_step=config['valid_step'],lr_scheduler=lr_scheduler)"
      ],
      "id": "injured-anderson",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-15T11:37:51.215825Z",
          "iopub.status.busy": "2021-06-15T11:37:51.215160Z",
          "iopub.status.idle": "2021-06-15T12:14:50.690844Z",
          "shell.execute_reply": "2021-06-15T12:14:50.692030Z",
          "shell.execute_reply.started": "2021-06-15T11:32:42.390093Z"
        },
        "papermill": {
          "duration": 2219.502967,
          "end_time": "2021-06-15T12:14:50.692245",
          "exception": false,
          "start_time": "2021-06-15T11:37:51.189278",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fourth-tactics",
        "outputId": "56832ebb-aa08-4000-8b7a-1fc942ec3c29"
      },
      "source": [
        "for f in range(config['nfolds']):\n",
        "    run(f)\n",
        "wandb.finish()"
      ],
      "id": "fourth-tactics",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at /clrp_roberta_base_chk were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.decoder.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at /clrp_roberta_base_chk and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fold: 0\n",
            "Epoch Started:0\n",
            "epoch:0 | Train Loss:1.4068840742111206 | Validation loss:1.2161705642938614\n",
            "Validation loss Decreased from 9999 to 1.2161705642938614\n",
            "epoch:0 | Train Loss:1.0451854250647805 | Validation loss:0.9129453400770823\n",
            "Validation loss Decreased from 1.2161705642938614 to 0.9129453400770823\n",
            "epoch:0 | Train Loss:0.9762883299872989 | Validation loss:0.7206566606958708\n",
            "Validation loss Decreased from 0.9129453400770823 to 0.7206566606958708\n",
            "epoch:0 | Train Loss:0.9129054296401239 | Validation loss:0.7085926350620058\n",
            "Validation loss Decreased from 0.7206566606958708 to 0.7085926350620058\n",
            "epoch:0 | Train Loss:0.8570564294733652 | Validation loss:0.6572062960929341\n",
            "Validation loss Decreased from 0.7085926350620058 to 0.6572062960929341\n",
            "epoch:0 | Train Loss:0.7870819641918433 | Validation loss:0.6549994680616591\n",
            "Validation loss Decreased from 0.6572062960929341 to 0.6549994680616591\n",
            "epoch:0 | Train Loss:0.7580922531410003 | Validation loss:0.6315210031138526\n",
            "Validation loss Decreased from 0.6549994680616591 to 0.6315210031138526\n",
            "epoch:0 | Train Loss:0.7371630955625463 | Validation loss:0.5700910521878136\n",
            "Validation loss Decreased from 0.6315210031138526 to 0.5700910521878136\n",
            "epoch:0 | Train Loss:0.6807226058636003 | Validation loss:0.5383704528212547\n",
            "Validation loss Decreased from 0.5700910521878136 to 0.5383704528212547\n",
            "Epoch Started:1\n",
            "epoch:1 | Train Loss:0.47812786747197633 | Validation loss:0.5363141488697794\n",
            "Validation loss Decreased from 0.5383704528212547 to 0.5363141488697794\n",
            "epoch:1 | Train Loss:0.47163163797116614 | Validation loss:0.5075083788898256\n",
            "Validation loss Decreased from 0.5363141488697794 to 0.5075083788898256\n",
            "epoch:1 | Train Loss:0.4654238263841804 | Validation loss:0.47453830391168594\n",
            "Validation loss Decreased from 0.5075083788898256 to 0.47453830391168594\n",
            "Epoch Started:2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at /clrp_roberta_base_chk were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.decoder.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at /clrp_roberta_base_chk and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fold: 1\n",
            "Epoch Started:0\n",
            "epoch:0 | Train Loss:1.1066762208938599 | Validation loss:1.2153713073995378\n",
            "Validation loss Decreased from 9999 to 1.2153713073995378\n",
            "epoch:0 | Train Loss:1.0005325566638599 | Validation loss:0.8558776817388005\n",
            "Validation loss Decreased from 1.2153713073995378 to 0.8558776817388005\n",
            "epoch:0 | Train Loss:0.8771779054687137 | Validation loss:0.7444211981362767\n",
            "Validation loss Decreased from 0.8558776817388005 to 0.7444211981362767\n",
            "epoch:0 | Train Loss:0.8128736411652914 | Validation loss:0.6984637007117271\n",
            "Validation loss Decreased from 0.7444211981362767 to 0.6984637007117271\n",
            "epoch:0 | Train Loss:0.7719919447805367 | Validation loss:0.6567064598202705\n",
            "Validation loss Decreased from 0.6984637007117271 to 0.6567064598202705\n",
            "epoch:0 | Train Loss:0.7133531163276081 | Validation loss:0.6417399495840073\n",
            "Validation loss Decreased from 0.6567064598202705 to 0.6417399495840073\n",
            "epoch:0 | Train Loss:0.7083028777615055 | Validation loss:0.5952000377906693\n",
            "Validation loss Decreased from 0.6417399495840073 to 0.5952000377906693\n",
            "epoch:0 | Train Loss:0.6710864231606161 | Validation loss:0.5658936616447237\n",
            "Validation loss Decreased from 0.5952000377906693 to 0.5658936616447237\n",
            "Epoch Started:1\n",
            "epoch:1 | Train Loss:0.48824298285668893 | Validation loss:0.5532630292905701\n",
            "Validation loss Decreased from 0.5658936616447237 to 0.5532630292905701\n",
            "epoch:1 | Train Loss:0.48113831877708435 | Validation loss:0.5261795529060893\n",
            "Validation loss Decreased from 0.5532630292905701 to 0.5261795529060893\n",
            "epoch:1 | Train Loss:0.4782467210879091 | Validation loss:0.5196558228797383\n",
            "Validation loss Decreased from 0.5261795529060893 to 0.5196558228797383\n",
            "epoch:1 | Train Loss:0.4657262923693893 | Validation loss:0.5150735047128465\n",
            "Validation loss Decreased from 0.5196558228797383 to 0.5150735047128465\n",
            "Epoch Started:2\n",
            "epoch:2 | Train Loss:0.36869581256593975 | Validation loss:0.5112516060471535\n",
            "Validation loss Decreased from 0.5150735047128465 to 0.5112516060471535\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at /clrp_roberta_base_chk were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.decoder.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at /clrp_roberta_base_chk and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fold: 2\n",
            "Epoch Started:0\n",
            "epoch:0 | Train Loss:1.4777355194091797 | Validation loss:1.2196833540995915\n",
            "Validation loss Decreased from 9999 to 1.2196833540995915\n",
            "epoch:0 | Train Loss:1.0937653888355603 | Validation loss:0.9396527641349368\n",
            "Validation loss Decreased from 1.2196833540995915 to 0.9396527641349368\n",
            "epoch:0 | Train Loss:0.9802610874176025 | Validation loss:0.7521521904402309\n",
            "Validation loss Decreased from 0.9396527641349368 to 0.7521521904402309\n",
            "epoch:0 | Train Loss:0.8291968906798014 | Validation loss:0.6972550774614016\n",
            "Validation loss Decreased from 0.7521521904402309 to 0.6972550774614016\n",
            "epoch:0 | Train Loss:0.7935750157225365 | Validation loss:0.6855436282025443\n",
            "Validation loss Decreased from 0.6972550774614016 to 0.6855436282025443\n",
            "epoch:0 | Train Loss:0.7723565775840009 | Validation loss:0.5768228529228104\n",
            "Validation loss Decreased from 0.6855436282025443 to 0.5768228529228104\n",
            "epoch:0 | Train Loss:0.7585545778274536 | Validation loss:0.5683875911765628\n",
            "Validation loss Decreased from 0.5768228529228104 to 0.5683875911765628\n",
            "epoch:0 | Train Loss:0.7414198403741107 | Validation loss:0.5502792340185907\n",
            "Validation loss Decreased from 0.5683875911765628 to 0.5502792340185907\n",
            "epoch:0 | Train Loss:0.6874455708610124 | Validation loss:0.5403299729029337\n",
            "Validation loss Decreased from 0.5502792340185907 to 0.5403299729029337\n",
            "Epoch Started:1\n",
            "epoch:1 | Train Loss:0.4908748652253832 | Validation loss:0.5391041081812646\n",
            "Validation loss Decreased from 0.5403299729029337 to 0.5391041081812646\n",
            "epoch:1 | Train Loss:0.46518966171049303 | Validation loss:0.5309298361341158\n",
            "Validation loss Decreased from 0.5391041081812646 to 0.5309298361341158\n",
            "epoch:1 | Train Loss:0.4622993338398817 | Validation loss:0.5231083581844965\n",
            "Validation loss Decreased from 0.5309298361341158 to 0.5231083581844965\n",
            "epoch:1 | Train Loss:0.46939585489385266 | Validation loss:0.504252799683147\n",
            "Validation loss Decreased from 0.5231083581844965 to 0.504252799683147\n",
            "Epoch Started:2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at /clrp_roberta_base_chk were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.decoder.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at /clrp_roberta_base_chk and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fold: 3\n",
            "Epoch Started:0\n",
            "epoch:0 | Train Loss:1.254278540611267 | Validation loss:1.1313355614741643\n",
            "Validation loss Decreased from 9999 to 1.1313355614741643\n",
            "epoch:0 | Train Loss:0.9709238843484358 | Validation loss:0.8835806647936503\n",
            "Validation loss Decreased from 1.1313355614741643 to 0.8835806647936503\n",
            "epoch:0 | Train Loss:0.9141639371713003 | Validation loss:0.8484592371516757\n",
            "Validation loss Decreased from 0.8835806647936503 to 0.8484592371516757\n",
            "epoch:0 | Train Loss:0.8656892170829158 | Validation loss:0.6269961024324099\n",
            "Validation loss Decreased from 0.8484592371516757 to 0.6269961024324099\n",
            "epoch:0 | Train Loss:0.8117559573999266 | Validation loss:0.6070783568753136\n",
            "Validation loss Decreased from 0.6269961024324099 to 0.6070783568753136\n",
            "epoch:0 | Train Loss:0.7220978457250713 | Validation loss:0.5685998242762353\n",
            "Validation loss Decreased from 0.6070783568753136 to 0.5685998242762353\n",
            "epoch:0 | Train Loss:0.6964055839741584 | Validation loss:0.5159831982519891\n",
            "Validation loss Decreased from 0.5685998242762353 to 0.5159831982519891\n",
            "Epoch Started:1\n",
            "epoch:1 | Train Loss:0.4588143561707168 | Validation loss:0.5073899750908216\n",
            "Validation loss Decreased from 0.5159831982519891 to 0.5073899750908216\n",
            "epoch:1 | Train Loss:0.46303926009527396 | Validation loss:0.4970702628294627\n",
            "Validation loss Decreased from 0.5073899750908216 to 0.4970702628294627\n",
            "epoch:1 | Train Loss:0.46714856087668866 | Validation loss:0.48222872283723617\n",
            "Validation loss Decreased from 0.4970702628294627 to 0.48222872283723617\n",
            "Epoch Started:2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at /clrp_roberta_base_chk were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.decoder.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at /clrp_roberta_base_chk and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fold: 4\n",
            "Epoch Started:0\n",
            "epoch:0 | Train Loss:1.4734455347061157 | Validation loss:1.3700453614195187\n",
            "Validation loss Decreased from 9999 to 1.3700453614195187\n",
            "epoch:0 | Train Loss:1.1426657167347996 | Validation loss:0.951818413204617\n",
            "Validation loss Decreased from 1.3700453614195187 to 0.951818413204617\n",
            "epoch:0 | Train Loss:1.0877674136843 | Validation loss:0.93420120411449\n",
            "Validation loss Decreased from 0.951818413204617 to 0.93420120411449\n",
            "epoch:0 | Train Loss:1.0160935348080051 | Validation loss:0.811138242483139\n",
            "Validation loss Decreased from 0.93420120411449 to 0.811138242483139\n",
            "epoch:0 | Train Loss:1.0052358086516218 | Validation loss:0.7504057751761543\n",
            "Validation loss Decreased from 0.811138242483139 to 0.7504057751761543\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-15T12:14:50.849074Z",
          "iopub.status.busy": "2021-06-15T12:14:50.848310Z",
          "iopub.status.idle": "2021-06-15T12:14:50.852870Z",
          "shell.execute_reply": "2021-06-15T12:14:50.853483Z",
          "shell.execute_reply.started": "2021-06-15T09:36:17.845824Z"
        },
        "papermill": {
          "duration": 0.085355,
          "end_time": "2021-06-15T12:14:50.853660",
          "exception": false,
          "start_time": "2021-06-15T12:14:50.768305",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "duplicate-trade",
        "outputId": "6af30127-eca0-4490-ff0e-3ccab7fef3b3"
      },
      "source": [
        "os.listdir('./gdrive/MyDrive/Kaggle_CommonLit/')"
      ],
      "id": "duplicate-trade",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['sample_submission.csv',\n",
              " 'train.csv',\n",
              " 'test.csv',\n",
              " 'cleaned_train.csv',\n",
              " 'cleaned_test.csv',\n",
              " 'clrp_roberta_base_chk',\n",
              " 'text.txt',\n",
              " 'Transformer_basic.ipynb']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-15T12:14:50.974862Z",
          "iopub.status.busy": "2021-06-15T12:14:50.973659Z",
          "iopub.status.idle": "2021-06-15T12:14:50.976296Z",
          "shell.execute_reply": "2021-06-15T12:14:50.975905Z",
          "shell.execute_reply.started": "2021-06-15T09:35:54.071068Z"
        },
        "papermill": {
          "duration": 0.05348,
          "end_time": "2021-06-15T12:14:50.976436",
          "exception": false,
          "start_time": "2021-06-15T12:14:50.922956",
          "status": "completed"
        },
        "tags": [],
        "id": "strategic-action"
      },
      "source": [
        "import random\n",
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "config = {\n",
        "    'learning_rate':2e-5,\n",
        "    'batch_size':32,\n",
        "    'epochs':10,\n",
        "    'nfolds':5,\n",
        "    'seed':42,\n",
        "    'max_len':256,\n",
        "}\n",
        "\n",
        "def seed_everything(seed=42):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONASSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "\n",
        "seed_everything(seed=config['seed'])"
      ],
      "id": "strategic-action",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-15T12:14:51.064318Z",
          "iopub.status.busy": "2021-06-15T12:14:51.063836Z",
          "iopub.status.idle": "2021-06-15T12:14:51.067500Z",
          "shell.execute_reply": "2021-06-15T12:14:51.067079Z",
          "shell.execute_reply.started": "2021-06-15T09:35:57.355452Z"
        },
        "papermill": {
          "duration": 0.049657,
          "end_time": "2021-06-15T12:14:51.067607",
          "exception": false,
          "start_time": "2021-06-15T12:14:51.017950",
          "status": "completed"
        },
        "tags": [],
        "id": "measured-academy"
      },
      "source": [
        "from torch.utils.data import Dataset\n",
        "\n",
        "class CLRPDataset(Dataset):\n",
        "    def __init__(self,df,tokenizer):\n",
        "        self.excerpt = df['excerpt'].to_numpy()\n",
        "        self.tokenizer = tokenizer\n",
        "    \n",
        "    def __getitem__(self,idx):\n",
        "        encode = self.tokenizer(self.excerpt[idx],return_tensors='pt',\n",
        "                                max_length=config['max_len'],\n",
        "                                padding='max_length',truncation=True)\n",
        "        return encode\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.excerpt)"
      ],
      "id": "measured-academy",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-15T12:14:51.156104Z",
          "iopub.status.busy": "2021-06-15T12:14:51.155621Z",
          "iopub.status.idle": "2021-06-15T12:14:51.158913Z",
          "shell.execute_reply": "2021-06-15T12:14:51.159280Z",
          "shell.execute_reply.started": "2021-06-15T09:36:01.029044Z"
        },
        "papermill": {
          "duration": 0.050619,
          "end_time": "2021-06-15T12:14:51.159411",
          "exception": false,
          "start_time": "2021-06-15T12:14:51.108792",
          "status": "completed"
        },
        "tags": [],
        "id": "nutritional-satisfaction"
      },
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class AttentionHead(nn.Module):\n",
        "    def __init__(self, in_features, hidden_dim, num_targets):\n",
        "        super().__init__()\n",
        "        self.in_features = in_features\n",
        "        self.middle_features = hidden_dim\n",
        "\n",
        "        self.W = nn.Linear(in_features, hidden_dim)\n",
        "        self.V = nn.Linear(hidden_dim, 1)\n",
        "        self.out_features = hidden_dim\n",
        "\n",
        "    def forward(self, features):\n",
        "        att = torch.tanh(self.W(features))\n",
        "\n",
        "        score = self.V(att)\n",
        "\n",
        "        attention_weights = torch.softmax(score, dim=1)\n",
        "\n",
        "        context_vector = attention_weights * features\n",
        "        context_vector = torch.sum(context_vector, dim=1)\n",
        "\n",
        "        return context_vector"
      ],
      "id": "nutritional-satisfaction",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-15T12:14:51.249479Z",
          "iopub.status.busy": "2021-06-15T12:14:51.248940Z",
          "iopub.status.idle": "2021-06-15T12:14:51.252572Z",
          "shell.execute_reply": "2021-06-15T12:14:51.252152Z",
          "shell.execute_reply.started": "2021-06-15T09:36:04.234043Z"
        },
        "papermill": {
          "duration": 0.051081,
          "end_time": "2021-06-15T12:14:51.252672",
          "exception": false,
          "start_time": "2021-06-15T12:14:51.201591",
          "status": "completed"
        },
        "tags": [],
        "id": "literary-cedar"
      },
      "source": [
        "class Model(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Model,self).__init__()\n",
        "        self.roberta = AutoModel.from_pretrained('../input/roberta-base')    \n",
        "        self.head = AttentionHead(768,768,1)\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self.linear = nn.Linear(self.head.out_features,1)\n",
        "\n",
        "    def forward(self,**xb):\n",
        "        x = self.roberta(**xb)[0]\n",
        "        x = self.head(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.linear(x)\n",
        "        return x"
      ],
      "id": "literary-cedar",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-15T12:14:51.344517Z",
          "iopub.status.busy": "2021-06-15T12:14:51.343947Z",
          "iopub.status.idle": "2021-06-15T12:14:51.347573Z",
          "shell.execute_reply": "2021-06-15T12:14:51.347076Z",
          "shell.execute_reply.started": "2021-06-15T09:37:49.628049Z"
        },
        "papermill": {
          "duration": 0.052918,
          "end_time": "2021-06-15T12:14:51.347692",
          "exception": false,
          "start_time": "2021-06-15T12:14:51.294774",
          "status": "completed"
        },
        "tags": [],
        "id": "handed-cheese"
      },
      "source": [
        "from tqdm import tqdm\n",
        "def get_prediction(df,path,device='cuda'):        \n",
        "    model = Model()\n",
        "    model.load_state_dict(torch.load(path))\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    \n",
        "    tokenizer = AutoTokenizer.from_pretrained('roberta-base')\n",
        "    \n",
        "    test_ds = CLRPDataset(df,tokenizer)\n",
        "    test_dl = DataLoader(test_ds,\n",
        "                        batch_size = config[\"batch_size\"],\n",
        "                        shuffle=False,\n",
        "                        num_workers = 4,\n",
        "                        pin_memory=True)\n",
        "    \n",
        "    predictions = list()\n",
        "    for i, (inputs) in tqdm(enumerate(test_dl)):\n",
        "        inputs = {key:val.reshape(val.shape[0],-1).to(device) for key,val in inputs.items()}\n",
        "        outputs = model(**inputs)\n",
        "        outputs = outputs.cpu().detach().numpy().ravel().tolist()\n",
        "        predictions.extend(outputs)\n",
        "        \n",
        "    torch.cuda.empty_cache()\n",
        "    return np.array(predictions)"
      ],
      "id": "handed-cheese",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-15T12:14:51.435870Z",
          "iopub.status.busy": "2021-06-15T12:14:51.435285Z",
          "iopub.status.idle": "2021-06-15T12:15:20.559346Z",
          "shell.execute_reply": "2021-06-15T12:15:20.558898Z",
          "shell.execute_reply.started": "2021-06-15T09:37:54.380884Z"
        },
        "papermill": {
          "duration": 29.169549,
          "end_time": "2021-06-15T12:15:20.559491",
          "exception": false,
          "start_time": "2021-06-15T12:14:51.389942",
          "status": "completed"
        },
        "tags": [],
        "id": "global-xerox",
        "outputId": "4f6e7eaa-489d-47a6-8366-c75d1334051a"
      },
      "source": [
        "pred1 = get_prediction(test_data,'./model0/model0.bin')\n",
        "pred2 = get_prediction(test_data,'./model1/model1.bin')\n",
        "pred3 = get_prediction(test_data,'./model2/model2.bin')\n",
        "pred4 = get_prediction(test_data,'./model3/model3.bin')\n",
        "pred5 = get_prediction(test_data,'./model4/model4.bin')\n",
        "\n",
        "predictions = (pred1 + pred2 + pred3 + pred4 + pred5)/5"
      ],
      "id": "global-xerox",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1it [00:00,  5.42it/s]\n",
            "1it [00:00,  5.59it/s]\n",
            "1it [00:00,  6.00it/s]\n",
            "1it [00:00,  5.69it/s]\n",
            "1it [00:00,  5.69it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-15T12:15:20.658346Z",
          "iopub.status.busy": "2021-06-15T12:15:20.657855Z",
          "iopub.status.idle": "2021-06-15T12:15:21.039698Z",
          "shell.execute_reply": "2021-06-15T12:15:21.039218Z",
          "shell.execute_reply.started": "2021-06-15T09:38:40.846901Z"
        },
        "papermill": {
          "duration": 0.43509,
          "end_time": "2021-06-15T12:15:21.039839",
          "exception": false,
          "start_time": "2021-06-15T12:15:20.604749",
          "status": "completed"
        },
        "tags": [],
        "id": "capable-bidder"
      },
      "source": [
        "sample['target'] = predictions\n",
        "sample.to_csv('submission.csv',index=False)"
      ],
      "id": "capable-bidder",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-15T12:15:21.138059Z",
          "iopub.status.busy": "2021-06-15T12:15:21.137561Z",
          "iopub.status.idle": "2021-06-15T12:15:21.142444Z",
          "shell.execute_reply": "2021-06-15T12:15:21.142025Z",
          "shell.execute_reply.started": "2021-06-15T09:57:40.667352Z"
        },
        "papermill": {
          "duration": 0.057538,
          "end_time": "2021-06-15T12:15:21.142544",
          "exception": false,
          "start_time": "2021-06-15T12:15:21.085006",
          "status": "completed"
        },
        "tags": [],
        "id": "abstract-trial",
        "outputId": "f6be5330-a827-470c-e993-6938992e8cc3"
      },
      "source": [
        "sample"
      ],
      "id": "abstract-trial",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>c0f722661</td>\n",
              "      <td>-0.511399</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>f0953f0a5</td>\n",
              "      <td>-0.540758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0df072751</td>\n",
              "      <td>-0.504366</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>04caf4e0c</td>\n",
              "      <td>-2.530457</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0e63f8bea</td>\n",
              "      <td>-1.932504</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>12537fe78</td>\n",
              "      <td>-1.339906</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>965e592c0</td>\n",
              "      <td>0.219967</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          id    target\n",
              "0  c0f722661 -0.511399\n",
              "1  f0953f0a5 -0.540758\n",
              "2  0df072751 -0.504366\n",
              "3  04caf4e0c -2.530457\n",
              "4  0e63f8bea -1.932504\n",
              "5  12537fe78 -1.339906\n",
              "6  965e592c0  0.219967"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    }
  ]
}